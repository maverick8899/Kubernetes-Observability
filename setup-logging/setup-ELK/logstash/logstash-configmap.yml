apiVersion: v1
kind: ConfigMap
metadata:
    name: logstash-config
    namespace: logging
data:
    logstash.yml: |
        xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]
    logstash.conf: |
        input {
            beats {
                port => "5044"
          }
        }
        filter {
        grok {
          match => { "message" => '%{IP:client_ip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] "%{WORD:http_method} %{URIPATHPARAM:request_path} HTTP/%{NUMBER:http_version}" %{NUMBER:response_code} %{NUMBER:response_size} "%{URI:referrer}" "%{DATA:user_agent}"' }
        }

          date {
            match => [ "log_timestamp", "ISO8601" ]
            target => "@timestamp"
          }
        }
        output {
        if "elk-frontend" in [tags] {
          elasticsearch {
            hosts => [ "elasticsearch:9200" ]
            index => "elk-frontend_%{+YYYY.MM.dd}"
            }
          }
          else if "myservice" in [tags] {
          elasticsearch {
            hosts => [ "elasticsearch:9200" ]
            index => "logstash_myservice_%{+YYYY.MM.dd}"
            }
          }
          else {
          elasticsearch {
            hosts => [ "elasticsearch:9200" ]
            index => "logstash_default_%{+YYYY.MM.dd}"
            }
          }
        }

# apiVersion: v1
# kind: ConfigMap
# metadata:
#     name: logstash-config
#     namespace: logging
# data:
#     logstash.yml: |
#         xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]
#     logstash.conf: |
#         input {
#           beats {
#               type => "filebeat"
#               port => "9600"
#           }
#           http {
#             type => "pod"
#             #host => "0.0.0.0"
#             port => "9601"
#             codec => json
#           }
#         }

#         filter  {

#           mutate {
#             remove_field => [ "host" ]
#           }

#           if [kubernetes][labels][logstyle] == "nginx" {
#             #Nginx
#             grok {
#               match => { "message" => ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]}( \"%{DATA:[nginx][access][referrer]}\")?( \"%{DATA:[nginx][access][agent]}\")?",
#               "%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \\[%{HTTPDATE:[nginx][access][time]}\\] \"-\" %{NUMBER:[nginx][access][response_code]} -" ] }
#             }

#             # date {
#             #  match => [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
#             #  remove_field => "[nginx][access][time]"
#             # }

#             useragent {
#               source => "[nginx][access][agent]"
#               target => "[nginx][access][user_agent]"
#               remove_field => "[nginx][access][agent]"
#             }

#             geoip {
#               source => "[nginx][access][remote_ip]"
#               target => "[nginx][access][geoip]"
#             }
#           }
#           else if [type] == "filebeat" {
#             #filebeat
#             grok {
#               match => [ "message", "(?<timestamp>%{TIMESTAMP_ISO8601})\s+%{LOGLEVEL:level}\s+%{DATA}\s+%{GREEDYDATA:logmessage}" ]
#             }
#           }
#           else {
#             #HTD java
#             grok {
#               match => [ "message", "(?<timestamp>%{TIMESTAMP_ISO8601}) - \[(?<thread>[A-Za-z0-9-]+)\] %{LOGLEVEL:level}\s+(?<class>[A-Za-z0-9.]*\.[A-Za-z0-9#_]+)\s* - %{GREEDYDATA:logmessage}" ]
#             }
#           }
#         }

#         output {
#           # You can uncomment this line to investigate the generated events by the logstash.
#           #stdout { codec => rubydebug }
#           elasticsearch {
#               hosts => ["http://elasticsearch:9200"]
#               template_overwrite => false
#               manage_template => false
#               # The events will be stored in elasticsearch under previously defined index_prefix value.
#               index => "logstash-%{+YYYY.MM.dd}-000002"
#               sniffing => false
#           }
#         }

# ---
